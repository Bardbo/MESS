{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('pyflink': conda)",
   "metadata": {
    "interpreter": {
     "hash": "7bca0ce4226e4924b4545d046c28abde24880ab05ecbea8b1861f617641dc344"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.table import StreamTableEnvironment, DataTypes, CsvTableSource\n",
    "from pyflink.table.descriptors import Schema, OldCsv, FileSystem\n",
    "from pyflink.table.udf import udf\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 22.79132390022278 0.3798553983370463\n",
      "2 20.14496421813965 0.3357494036356608\n",
      "3 19.688557624816895 0.3281426270802816\n",
      "4 20.235044479370117 0.3372507413228353\n",
      "5 20.13295316696167 0.33554921944936117\n",
      "6 20.391184329986572 0.3398530721664429\n",
      "7 20.594365119934082 0.343239418665568\n",
      "8 20.731487035751343 0.34552478392918906\n",
      "9 20.503283977508545 0.3417213996251424\n",
      "10 20.800549268722534 0.3466758211453756\n",
      "11 20.86460566520691 0.34774342775344846\n",
      "12 20.210022687911987 0.3368337114651998\n",
      "13 20.41720676422119 0.3402867794036865\n",
      "14 20.504284858703613 0.34173808097839353\n",
      "15 20.466250896453857 0.3411041816075643\n",
      "16 20.7745258808136 0.34624209801356\n",
      "17 20.616384506225586 0.3436064084370931\n",
      "18 20.788537979125977 0.34647563298543294\n",
      "19 20.530308485031128 0.3421718080838521\n",
      "20 20.13795828819275 0.3356326381365458\n",
      "21 19.51940608024597 0.3253234346707662\n",
      "22 20.278082609176636 0.33796804348627724\n",
      "23 20.12494707107544 0.335415784517924\n",
      "24 20.73248863220215 0.34554147720336914\n",
      "25 20.85759997367859 0.3476266662279765\n",
      "26 20.517296075820923 0.34195493459701537\n",
      "27 20.413203239440918 0.34022005399068195\n",
      "28 20.71647357940674 0.34527455965677895\n",
      "29 20.633399486541748 0.3438899914423625\n",
      "30 20.807555675506592 0.3467925945917765\n",
      "31 20.953685522079468 0.3492280920346578\n",
      "639.8926243782043 10.664877072970073\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "for day in range(1, 32):\n",
    "    # 环境等设置\n",
    "    env = StreamExecutionEnvironment.get_execution_environment()\n",
    "    env.set_parallelism(1)\n",
    "    t_env = StreamTableEnvironment.create(env)\n",
    "    t_env.get_config().get_configuration().set_string(\"taskmanager.memory.task.off-heap.size\", '80m')\n",
    "    t_env.get_config().get_configuration().set_string(\"python.fn-execution.arrow.batch.size\", '300000')\n",
    "\n",
    "    # 输入表创建\n",
    "    t_env.connect(FileSystem().path('./data/pure_data')) \\\n",
    "        .with_format(OldCsv()\n",
    "                    .field('pickup_datetime', DataTypes.STRING())\n",
    "                    .field('dropoff_datetime', DataTypes.STRING())\n",
    "                    .field('pickup_longitude', DataTypes.FLOAT())\n",
    "                    .field('pickup_latitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_longitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_latitude', DataTypes.FLOAT())\n",
    "                    .field('O', DataTypes.BIGINT())\n",
    "                    .field('D', DataTypes.BIGINT())\n",
    "                    .field('duration', DataTypes.BIGINT())\n",
    "                    .field('weekday', DataTypes.BIGINT())\n",
    "                    .field('day', DataTypes.BIGINT())\n",
    "                    .field('hour', DataTypes.BIGINT())\n",
    "                    ) \\\n",
    "        .with_schema(Schema()\n",
    "                    .field('pickup_datetime', DataTypes.STRING())\n",
    "                    .field('dropoff_datetime', DataTypes.STRING())\n",
    "                    .field('pickup_longitude', DataTypes.FLOAT())\n",
    "                    .field('pickup_latitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_longitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_latitude', DataTypes.FLOAT())\n",
    "                    .field('O', DataTypes.BIGINT())\n",
    "                    .field('D', DataTypes.BIGINT())\n",
    "                    .field('duration', DataTypes.BIGINT())\n",
    "                    .field('weekday', DataTypes.BIGINT())\n",
    "                    .field('day', DataTypes.BIGINT())\n",
    "                    .field('hour', DataTypes.BIGINT())\n",
    "                    ) \\\n",
    "        .create_temporary_table('mySource')\n",
    "\n",
    "    # 输出表创建\n",
    "    t_env.connect(FileSystem().path('./data/day_data/day_' + str(day))) \\\n",
    "        .with_format(OldCsv()\n",
    "                    .field('pickup_datetime', DataTypes.STRING())\n",
    "                    .field('dropoff_datetime', DataTypes.STRING())\n",
    "                    .field('pickup_longitude', DataTypes.FLOAT())\n",
    "                    .field('pickup_latitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_longitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_latitude', DataTypes.FLOAT())\n",
    "                    .field('O', DataTypes.BIGINT())\n",
    "                    .field('D', DataTypes.BIGINT())\n",
    "                    .field('duration', DataTypes.BIGINT())\n",
    "                    .field('weekday', DataTypes.BIGINT())\n",
    "                    .field('day', DataTypes.BIGINT())\n",
    "                    .field('hour', DataTypes.BIGINT())\n",
    "                    ) \\\n",
    "        .with_schema(Schema()\n",
    "                    .field('pickup_datetime', DataTypes.STRING())\n",
    "                    .field('dropoff_datetime', DataTypes.STRING())\n",
    "                    .field('pickup_longitude', DataTypes.FLOAT())\n",
    "                    .field('pickup_latitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_longitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_latitude', DataTypes.FLOAT())\n",
    "                    .field('O', DataTypes.BIGINT())\n",
    "                    .field('D', DataTypes.BIGINT())\n",
    "                    .field('duration', DataTypes.BIGINT())\n",
    "                    .field('weekday', DataTypes.BIGINT())\n",
    "                    .field('day', DataTypes.BIGINT())\n",
    "                    .field('hour', DataTypes.BIGINT())\n",
    "                    ) \\\n",
    "        .create_temporary_table('mySink')\n",
    "    # 处理流程\n",
    "    t_env.from_path('mySource') \\\n",
    "        .where(f\"day = {day}\") \\\n",
    "        .insert_into('mySink')\n",
    "\n",
    "    # 执行与计时\n",
    "    start_time = time.time()\n",
    "    t_env.execute(\"job2\")\n",
    "    compute_time = time.time() - start_time\n",
    "    print(day, compute_time, compute_time / 60)\n",
    "sum_time = time.time() - st\n",
    "print(sum_time, sum_time/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}