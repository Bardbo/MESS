{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('pyflink': conda)",
   "display_name": "Python 3.7.9 64-bit ('pyflink': conda)",
   "metadata": {
    "interpreter": {
     "hash": "7bca0ce4226e4924b4545d046c28abde24880ab05ecbea8b1861f617641dc344"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.table import StreamTableEnvironment, DataTypes, CsvTableSource\n",
    "from pyflink.table.descriptors import Schema, OldCsv, FileSystem\n",
    "from pyflink.table.udf import udf\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 21.798309803009033 0.3633051633834839\n",
      "1 19.11193013191223 0.31853216886520386\n",
      "2 18.83568525314331 0.3139280875523885\n",
      "3 18.503390789031982 0.30838984648386636\n",
      "4 18.044984817504883 0.3007497469584147\n",
      "5 18.051990747451782 0.3008665124575297\n",
      "6 18.888731956481934 0.3148121992746989\n",
      "7 20.039751768112183 0.3339958628018697\n",
      "8 20.539194107055664 0.3423199017842611\n",
      "9 20.69132924079895 0.34485548734664917\n",
      "10 20.67331290245056 0.3445552150408427\n",
      "11 20.71635127067566 0.34527252117792767\n",
      "12 21.019620180130005 0.35032700300216674\n",
      "13 21.013179779052734 0.35021966298421225\n",
      "14 21.628498554229736 0.36047497590382893\n",
      "15 21.129441022872925 0.35215735038121543\n",
      "16 20.381054401397705 0.33968424002329506\n",
      "17 20.911524295806885 0.34852540493011475\n",
      "18 21.615147590637207 0.36025245984395343\n",
      "19 21.74626326560974 0.3624377210934957\n",
      "20 21.41997480392456 0.3569995800654093\n",
      "21 21.086679220199585 0.35144465366999306\n",
      "22 20.953561305999756 0.3492260217666626\n",
      "23 20.502161502838135 0.3417026917139689\n",
      "491.6881830692291 8.19480305115382\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "for hour in range(24):\n",
    "    # 环境等设置\n",
    "    env = StreamExecutionEnvironment.get_execution_environment()\n",
    "    env.set_parallelism(1)\n",
    "    t_env = StreamTableEnvironment.create(env)\n",
    "    t_env.get_config().get_configuration().set_string(\"taskmanager.memory.task.off-heap.size\", '80m')\n",
    "    t_env.get_config().get_configuration().set_string(\"python.fn-execution.arrow.batch.size\", '300000')\n",
    "\n",
    "    # 输入表创建\n",
    "    t_env.connect(FileSystem().path('./data/pure_data')) \\\n",
    "        .with_format(OldCsv()\n",
    "                    .field('pickup_datetime', DataTypes.STRING())\n",
    "                    .field('dropoff_datetime', DataTypes.STRING())\n",
    "                    .field('pickup_longitude', DataTypes.FLOAT())\n",
    "                    .field('pickup_latitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_longitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_latitude', DataTypes.FLOAT())\n",
    "                    .field('O', DataTypes.BIGINT())\n",
    "                    .field('D', DataTypes.BIGINT())\n",
    "                    .field('duration', DataTypes.BIGINT())\n",
    "                    .field('weekday', DataTypes.BIGINT())\n",
    "                    .field('day', DataTypes.BIGINT())\n",
    "                    .field('hour', DataTypes.BIGINT())\n",
    "                    ) \\\n",
    "        .with_schema(Schema()\n",
    "                    .field('pickup_datetime', DataTypes.STRING())\n",
    "                    .field('dropoff_datetime', DataTypes.STRING())\n",
    "                    .field('pickup_longitude', DataTypes.FLOAT())\n",
    "                    .field('pickup_latitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_longitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_latitude', DataTypes.FLOAT())\n",
    "                    .field('O', DataTypes.BIGINT())\n",
    "                    .field('D', DataTypes.BIGINT())\n",
    "                    .field('duration', DataTypes.BIGINT())\n",
    "                    .field('weekday', DataTypes.BIGINT())\n",
    "                    .field('day', DataTypes.BIGINT())\n",
    "                    .field('hour', DataTypes.BIGINT())\n",
    "                    ) \\\n",
    "        .create_temporary_table('mySource')\n",
    "\n",
    "    # 输出表创建\n",
    "    t_env.connect(FileSystem().path('./data/hour_data/hour_' + str(hour))) \\\n",
    "        .with_format(OldCsv()\n",
    "                    .field('pickup_datetime', DataTypes.STRING())\n",
    "                    .field('dropoff_datetime', DataTypes.STRING())\n",
    "                    .field('pickup_longitude', DataTypes.FLOAT())\n",
    "                    .field('pickup_latitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_longitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_latitude', DataTypes.FLOAT())\n",
    "                    .field('O', DataTypes.BIGINT())\n",
    "                    .field('D', DataTypes.BIGINT())\n",
    "                    .field('duration', DataTypes.BIGINT())\n",
    "                    .field('weekday', DataTypes.BIGINT())\n",
    "                    .field('day', DataTypes.BIGINT())\n",
    "                    .field('hour', DataTypes.BIGINT())\n",
    "                    ) \\\n",
    "        .with_schema(Schema()\n",
    "                    .field('pickup_datetime', DataTypes.STRING())\n",
    "                    .field('dropoff_datetime', DataTypes.STRING())\n",
    "                    .field('pickup_longitude', DataTypes.FLOAT())\n",
    "                    .field('pickup_latitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_longitude', DataTypes.FLOAT())\n",
    "                    .field('dropoff_latitude', DataTypes.FLOAT())\n",
    "                    .field('O', DataTypes.BIGINT())\n",
    "                    .field('D', DataTypes.BIGINT())\n",
    "                    .field('duration', DataTypes.BIGINT())\n",
    "                    .field('weekday', DataTypes.BIGINT())\n",
    "                    .field('day', DataTypes.BIGINT())\n",
    "                    .field('hour', DataTypes.BIGINT())\n",
    "                    ) \\\n",
    "        .create_temporary_table('mySink')\n",
    "    # 处理流程\n",
    "    t_env.from_path('mySource') \\\n",
    "        .where(f\"hour = {hour}\") \\\n",
    "        .insert_into('mySink')\n",
    "\n",
    "    # 执行与计时\n",
    "    start_time = time.time()\n",
    "    t_env.execute(\"job2\")\n",
    "    compute_time = time.time() - start_time\n",
    "    print(hour, compute_time, compute_time / 60)\n",
    "sum_time = time.time() - st\n",
    "print(sum_time, sum_time/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}